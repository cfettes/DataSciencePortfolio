{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition with Bi-Directional LSTMs\n",
    "\n",
    "This notebook uses pre-tagged data to train a model to predict entities within text.\n",
    "\n",
    "**Data:**\n",
    "The data used to train the models is the annotated GMB corpus dataset found on Kaggle, through the following link: https://www.kaggle.com/shoumikgoswami/annotated-gmb-corpus/data\n",
    "The dataset is a table with a row per word along with its POS and tag and the sentence number that it belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore the data\n",
    "\n",
    "The sentence of the data will first be transformed into a list of tuples containing the word, POS and tag. Tokens per sentence will then be visualised using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"entity-annotated-corpus/ner_dataset.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences:  47959\n",
      "Number of words in the dataset:  35178\n",
      "Tags: ['I-org', 'B-tim', 'I-nat', 'O', 'I-tim', 'B-eve', 'B-geo', 'B-nat', 'B-gpe', 'I-gpe', 'B-per', 'B-art', 'I-art', 'I-eve', 'I-per', 'B-org', 'I-geo']\n",
      "Number of Labels:  17\n",
      "Dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS    Tag\n",
       "0  Sentence: 1      Thousands  NNS      O\n",
       "1  Sentence: 1             of   IN      O\n",
       "2  Sentence: 1  demonstrators  NNS      O\n",
       "3  Sentence: 1           have  VBP      O\n",
       "4  Sentence: 1        marched  VBN      O\n",
       "5  Sentence: 1        through   IN      O\n",
       "6  Sentence: 1         London  NNP  B-geo\n",
       "7  Sentence: 1             to   TO      O\n",
       "8  Sentence: 1        protest   VB      O\n",
       "9  Sentence: 1            the   DT      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of sentences: \", len(data.groupby(['Sentence #'])))\n",
    "\n",
    "words = list(set(data[\"Word\"].values))\n",
    "n_words = len(words)\n",
    "print(\"Number of words in the dataset: \", n_words)\n",
    "\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "print(\"Tags:\", tags)\n",
    "n_tags = len(tags)\n",
    "print(\"Number of Labels: \", n_tags)\n",
    "\n",
    "print(\"Dataset sample:\")\n",
    "\n",
    "# Show the first 10 rows\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SentenceGetter(object):\n",
    "    \"\"\"Class to Get the sentence in this format:\n",
    "    [(Token_1, Part_of_Speech_1, Tag_1), ..., (Token_n, Part_of_Speech_1, Tag_1)]\"\"\"\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Args:\n",
    "            data is the pandas.DataFrame which contains the above dataset\"\"\"\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        \"\"\"Return one sentence\"\"\"\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "\n",
    "# Get all the sentences\n",
    "sentences = getter.sentences\n",
    "\n",
    "# Plot sentence by lenght\n",
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.title('Token per sentence')\n",
    "plt.xlabel('Len (number of token)')\n",
    "plt.ylabel('# samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 104\n"
     ]
    }
   ],
   "source": [
    "print ('Maximum sequence length:', max([len(s) for s in sentences]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 140\n",
    "word_embedding_size = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "This step will involve:\n",
    "+ word2idx dictionary to convert each word to a corresponding integer ID and the tag2idx to do the same for the labels \n",
    "+ in order to feed the text into the models, all texts should be the same length. The sequence.pad_sequences() method and maxlen variable; all texts longer than maxlen are truncated and shorter texts are padded to get them to the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35179"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create word list of all words in corpus\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocabulary Key:word -> Value:token_index\n",
    "word2idx = {w: i for i, w in enumerate(words)}\n",
    "\n",
    "#Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "#Vocabulary Key:Label/Tag -> Value:tag_index\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "\n",
    "#Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "#Convert each sentence from list of Token to list of word_index\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "#Padding each sentence to have the same length\n",
    "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=n_words - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Tag/Label to tag_index\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "#Padding each sentence to have the same length\n",
    "y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "#One-Hot encode\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Models\n",
    "\n",
    "Evaluating these models, F1 score will be used primarily. Accuracy is not the best metric as O tag will likely have the highest frequency, and so if a model were to predict all tags as being O it could still obtain a high accuracy rate, where in fact the O tag is the one of least importance - it is the other tags that we are interested in.\n",
    "\n",
    "### Single Bidirectional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "\n",
    "input = Input(shape=(maxlen,))\n",
    "lstm_model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "lstm_model = Dropout(0.1)(lstm_model)\n",
    "lstm_model = Bidirectional(LSTM(units=word_embedding_size, return_sequences=True, recurrent_dropout=0.1))(lstm_model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(lstm_model)  #softmax output layer\n",
    "\n",
    "lstm_model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 140, 300)          10553700  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 140, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 140, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 140, 17)           10217     \n",
      "=================================================================\n",
      "Total params: 12,006,317\n",
      "Trainable params: 12,006,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Saving the best model only\n",
    "filepath=\"ner-lstm-model-{val_accuracy:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30693 samples, validate on 7674 samples\n",
      "Epoch 1/10\n",
      "30693/30693 [==============================] - 579s 19ms/step - loss: 0.0562 - accuracy: 0.9869 - val_loss: 0.0197 - val_accuracy: 0.9942\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99421, saving model to ner-lstm-model-0.994.hdf5\n",
      "Epoch 2/10\n",
      "30693/30693 [==============================] - 555s 18ms/step - loss: 0.0153 - accuracy: 0.9954 - val_loss: 0.0174 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.99421 to 0.99467, saving model to ner-lstm-model-0.995.hdf5\n",
      "Epoch 3/10\n",
      "30693/30693 [==============================] - 549s 18ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0171 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.99467 to 0.99490, saving model to ner-lstm-model-0.995.hdf5\n",
      "Epoch 4/10\n",
      "30693/30693 [==============================] - 547s 18ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0180 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.99490\n",
      "Epoch 5/10\n",
      "30693/30693 [==============================] - 549s 18ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0195 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.99490\n",
      "Epoch 6/10\n",
      "30693/30693 [==============================] - 553s 18ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0202 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99490\n",
      "Epoch 7/10\n",
      "30693/30693 [==============================] - 532s 17ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0219 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99490\n",
      "Epoch 8/10\n",
      "30693/30693 [==============================] - 527s 17ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0238 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99490\n",
      "Epoch 9/10\n",
      "30693/30693 [==============================] - 528s 17ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0251 - val_accuracy: 0.9943\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99490\n",
      "Epoch 10/10\n",
      "30693/30693 [==============================] - 527s 17ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0275 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99490\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(X_train, np.array(y_train), batch_size=32, epochs=10, validation_split=0.2, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model\n",
    "input = Input(shape=(maxlen,))\n",
    "lstm_model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "lstm_model = Dropout(0.1)(lstm_model)\n",
    "lstm_model = Bidirectional(LSTM(units=word_embedding_size, return_sequences=True, recurrent_dropout=0.1))(lstm_model)\n",
    "out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(lstm_model)  # softmax output layer\n",
    "\n",
    "lstm_model = Model(input, out)\n",
    "lstm_model.load_weights('ner-lstm-model-0.995.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592/9592 [==============================] - 109s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "#function to convert predictios from index to tags\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "\n",
    "test_pred = lstm_model.predict(X_test, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 80.9%\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.25      0.01      0.03        73\n",
      "       B-eve       0.55      0.20      0.29        60\n",
      "       B-geo       0.84      0.91      0.87      7349\n",
      "       B-gpe       0.96      0.93      0.95      3165\n",
      "       B-nat       0.50      0.17      0.26        40\n",
      "       B-org       0.78      0.71      0.75      4025\n",
      "       B-per       0.84      0.80      0.82      3396\n",
      "       B-tim       0.91      0.88      0.90      4140\n",
      "       I-art       0.00      0.00      0.00        55\n",
      "       I-eve       0.25      0.28      0.26        43\n",
      "       I-geo       0.79      0.80      0.80      1505\n",
      "       I-gpe       1.00      0.51      0.68        37\n",
      "       I-nat       0.00      0.00      0.00        12\n",
      "       I-org       0.81      0.75      0.78      3228\n",
      "       I-per       0.87      0.84      0.85      3468\n",
      "       I-tim       0.85      0.69      0.76      1316\n",
      "           O       1.00      1.00      1.00   1310968\n",
      "\n",
      "    accuracy                           0.99   1342880\n",
      "   macro avg       0.66      0.56      0.59   1342880\n",
      "weighted avg       0.99      0.99      0.99   1342880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a CRF Layer\n",
    "\n",
    "Conditional Random Fields (CRFs) are intended to do task-specific predictions. It is a probabilistic discriminative model. The conditional random field is used for predicting the sequences that use the contextual information to add information that will be used by the model to make correct predictions.\n",
    "\n",
    "The power of CRF models is particularly useful when the model predicts many variables that are interdependent. NER is a problem of identifying the entities from the text and classifying the entities into a person, location, organisation etc. The main challenge behind the NER problem is that the entities that are too rare to appear in training set due to which the model must identify based only on context. The naive approach to this problem is to classify each word independently. The main problem with this approach is it assumes that named entity labels are independent which is not the case. To tackle this problem CRFs are used where input data is sequence and output is also a sequence and previous context needs to be taken into account when predicting on a data point. For this purpose, a feature function that will have multiple input values is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "input = Input(shape=(maxlen,))\n",
    "\n",
    "#Embedding Layer\n",
    "lstmcrf_model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "lstmcrf_model = Dropout(0.1)(lstmcrf_model)\n",
    "#BI-LSTM Layer\n",
    "lstmcrf_model = Bidirectional(LSTM(units=word_embedding_size,return_sequences=True,recurrent_dropout=0.1))(lstmcrf_model)\n",
    "\n",
    "#TimeDistributed Layer\n",
    "lstmcrf_model = TimeDistributed(Dense(n_tags, activation=\"relu\"))(lstmcrf_model)  \n",
    "\n",
    "#CRF Layer\n",
    "crf = CRF(n_tags)\n",
    "\n",
    "out = crf(lstmcrf_model)  \n",
    "\n",
    "#output\n",
    "lstmcrf_model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 140, 300)          10553700  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 140, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 140, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 140, 17)           10217     \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 140, 17)           629       \n",
      "=================================================================\n",
      "Total params: 12,006,946\n",
      "Trainable params: 12,006,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 34530 samples, validate on 3837 samples\n",
      "Epoch 1/10\n",
      "34530/34530 [==============================] - 601s 17ms/step - loss: 0.0851 - crf_viterbi_accuracy: 0.9797 - accuracy: 0.0025 - val_loss: 0.0294 - val_crf_viterbi_accuracy: 0.9903 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99029, saving model to ner-lstmcrf-model-0.990.hdf5\n",
      "Epoch 2/10\n",
      "34530/34530 [==============================] - 590s 17ms/step - loss: 0.0155 - crf_viterbi_accuracy: 0.9936 - accuracy: 0.0025 - val_loss: 0.0102 - val_crf_viterbi_accuracy: 0.9941 - val_accuracy: 0.9941\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.99029 to 0.99409, saving model to ner-lstmcrf-model-0.994.hdf5\n",
      "Epoch 3/10\n",
      "34530/34530 [==============================] - 571s 17ms/step - loss: 0.0032 - crf_viterbi_accuracy: 0.9956 - accuracy: 0.0025 - val_loss: 0.0041 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.99409 to 0.99464, saving model to ner-lstmcrf-model-0.995.hdf5\n",
      "Epoch 4/10\n",
      "34530/34530 [==============================] - 564s 16ms/step - loss: -0.0038 - crf_viterbi_accuracy: 0.9964 - accuracy: 0.0025 - val_loss: -8.2227e-04 - val_crf_viterbi_accuracy: 0.9948 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.99464 to 0.99480, saving model to ner-lstmcrf-model-0.995.hdf5\n",
      "Epoch 5/10\n",
      "34530/34530 [==============================] - 577s 17ms/step - loss: -0.0096 - crf_viterbi_accuracy: 0.9969 - accuracy: 0.0025 - val_loss: -0.0050 - val_crf_viterbi_accuracy: 0.9949 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.99480 to 0.99486, saving model to ner-lstmcrf-model-0.995.hdf5\n",
      "Epoch 6/10\n",
      "34530/34530 [==============================] - 565s 16ms/step - loss: -0.0149 - crf_viterbi_accuracy: 0.9973 - accuracy: 0.0025 - val_loss: -0.0087 - val_crf_viterbi_accuracy: 0.9948 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.99486\n",
      "Epoch 7/10\n",
      "34530/34530 [==============================] - 566s 16ms/step - loss: -0.0200 - crf_viterbi_accuracy: 0.9977 - accuracy: 0.0025 - val_loss: -0.0112 - val_crf_viterbi_accuracy: 0.9945 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99486\n",
      "Epoch 8/10\n",
      "34530/34530 [==============================] - 564s 16ms/step - loss: -0.0248 - crf_viterbi_accuracy: 0.9980 - accuracy: 0.0025 - val_loss: -0.0146 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.99486\n",
      "Epoch 9/10\n",
      "34530/34530 [==============================] - 564s 16ms/step - loss: -0.0295 - crf_viterbi_accuracy: 0.9983 - accuracy: 0.0025 - val_loss: -0.0176 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99486\n",
      "Epoch 10/10\n",
      "34530/34530 [==============================] - 573s 17ms/step - loss: -0.0341 - crf_viterbi_accuracy: 0.9986 - accuracy: 0.0025 - val_loss: -0.0211 - val_crf_viterbi_accuracy: 0.9944 - val_accuracy: 0.9944\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.99486\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Optimiser \n",
    "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "#Compile model\n",
    "lstmcrf_model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
    "lstmcrf_model.summary()\n",
    "\n",
    "#Saving the best model only\n",
    "filepath=\"ner-lstmcrf-model-{val_accuracy:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Fit the best model\n",
    "history = lstmcrf_model.fit(X_train, np.array(y_train), batch_size=32, epochs=10, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best weights\n",
    "input = Input(shape=(maxlen,))\n",
    "\n",
    "#Embedding Layer\n",
    "lstmcrf_model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "lstmcrf_model = Dropout(0.1)(lstmcrf_model)\n",
    "#BI-LSTM Layer\n",
    "lstmcrf_model = Bidirectional(LSTM(units=word_embedding_size,return_sequences=True,recurrent_dropout=0.1))(lstmcrf_model)\n",
    "\n",
    "#TimeDistributed Layer\n",
    "lstmcrf_model = TimeDistributed(Dense(n_tags, activation=\"relu\"))(lstmcrf_model)  \n",
    "\n",
    "#CRF Layer\n",
    "crf = CRF(n_tags)\n",
    "\n",
    "out = crf(lstmcrf_model)  \n",
    "\n",
    "#output\n",
    "lstmcrf_model = Model(input, out)\n",
    "\n",
    "lstmcrf_model.load_weights('ner-lstmcrf-model-0.995.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592/9592 [==============================] - 102s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = lstmcrf_model.predict(X_test, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 82.2%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        73\n",
      "       B-eve       1.00      0.22      0.36        60\n",
      "       B-geo       0.84      0.89      0.87      7349\n",
      "       B-gpe       0.95      0.93      0.94      3165\n",
      "       B-nat       0.00      0.00      0.00        40\n",
      "       B-org       0.77      0.69      0.73      4025\n",
      "       B-per       0.86      0.79      0.82      3396\n",
      "       B-tim       0.91      0.87      0.89      4140\n",
      "       I-art       0.00      0.00      0.00        55\n",
      "       I-eve       0.00      0.00      0.00        43\n",
      "       I-geo       0.84      0.76      0.80      1505\n",
      "       I-gpe       1.00      0.03      0.05        37\n",
      "       I-nat       0.00      0.00      0.00        12\n",
      "       I-org       0.76      0.77      0.77      3228\n",
      "       I-per       0.87      0.84      0.85      3468\n",
      "       I-tim       0.83      0.69      0.75      1316\n",
      "           O       1.00      1.00      1.00   1310968\n",
      "\n",
      "    accuracy                           0.99   1342880\n",
      "   macro avg       0.63      0.50      0.52   1342880\n",
      "weighted avg       0.99      0.99      0.99   1342880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding an Additional LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "import keras as k\n",
    "from keras_contrib.layers import CRF\n",
    "\n",
    "input = Input(shape=(maxlen,))\n",
    "\n",
    "#Embedding Layer\n",
    "lstmcrf2_model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "lstmcrf2_model = Dropout(0.1)(lstmcrf2_model)\n",
    "#BI-LSTM Layer\n",
    "lstmcrf2_model = Bidirectional(LSTM(units=word_embedding_size, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.5, \n",
    "                           recurrent_dropout=0.5, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(lstmcrf2_model)\n",
    "lstmcrf2_model = LSTM(units=word_embedding_size * 2, \n",
    "             return_sequences=True, \n",
    "             dropout=0.5, \n",
    "             recurrent_dropout=0.5, \n",
    "             kernel_initializer=k.initializers.he_normal())(lstmcrf2_model)\n",
    "\n",
    "# TimeDistributed Layer\n",
    "lstmcrf2_model = TimeDistributed(Dense(n_tags, activation=\"relu\"))(lstmcrf2_model)  \n",
    "\n",
    "# CRF Layer\n",
    "crf = CRF(n_tags)\n",
    "\n",
    "out = crf(lstmcrf2_model)  \n",
    "\n",
    "#output\n",
    "lstmcrf2_model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 140, 300)          10553700  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 140, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 140, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 140, 600)          2882400   \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 140, 17)           10217     \n",
      "_________________________________________________________________\n",
      "crf_3 (CRF)                  (None, 140, 17)           629       \n",
      "=================================================================\n",
      "Total params: 14,889,346\n",
      "Trainable params: 14,889,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 34530 samples, validate on 3837 samples\n",
      "Epoch 1/20\n",
      "34530/34530 [==============================] - 1526s 44ms/step - loss: 0.0800 - crf_viterbi_accuracy: 0.9814 - accuracy: 0.0025 - val_loss: 0.0307 - val_crf_viterbi_accuracy: 0.9903 - val_accuracy: 0.9903\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99027, saving model to ner-lstmcrf2-model-0.990.hdf5\n",
      "Epoch 2/20\n",
      "34530/34530 [==============================] - 1470s 43ms/step - loss: 0.0217 - crf_viterbi_accuracy: 0.9924 - accuracy: 0.0025 - val_loss: 0.0143 - val_crf_viterbi_accuracy: 0.9938 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.99027 to 0.99379, saving model to ner-lstmcrf2-model-0.994.hdf5\n",
      "Epoch 3/20\n",
      "34530/34530 [==============================] - 1480s 43ms/step - loss: 0.0090 - crf_viterbi_accuracy: 0.9948 - accuracy: 0.0025 - val_loss: 0.0067 - val_crf_viterbi_accuracy: 0.9945 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.99379 to 0.99452, saving model to ner-lstmcrf2-model-0.995.hdf5\n",
      "Epoch 4/20\n",
      "34530/34530 [==============================] - 1483s 43ms/step - loss: 0.0018 - crf_viterbi_accuracy: 0.9957 - accuracy: 0.0025 - val_loss: 0.0017 - val_crf_viterbi_accuracy: 0.9947 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.99452 to 0.99470, saving model to ner-lstmcrf2-model-0.995.hdf5\n",
      "Epoch 5/20\n",
      "34530/34530 [==============================] - 1484s 43ms/step - loss: -0.0038 - crf_viterbi_accuracy: 0.9961 - accuracy: 0.0025 - val_loss: -0.0027 - val_crf_viterbi_accuracy: 0.9948 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.99470 to 0.99485, saving model to ner-lstmcrf2-model-0.995.hdf5\n",
      "Epoch 6/20\n",
      "34530/34530 [==============================] - 1475s 43ms/step - loss: -0.0089 - crf_viterbi_accuracy: 0.9964 - accuracy: 0.0025 - val_loss: -0.0070 - val_crf_viterbi_accuracy: 0.9950 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.99485 to 0.99496, saving model to ner-lstmcrf2-model-0.995.hdf5\n",
      "Epoch 7/20\n",
      "34530/34530 [==============================] - 1480s 43ms/step - loss: -0.0136 - crf_viterbi_accuracy: 0.9967 - accuracy: 0.0025 - val_loss: -0.0107 - val_crf_viterbi_accuracy: 0.9949 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.99496\n",
      "Epoch 8/20\n",
      "34530/34530 [==============================] - 1479s 43ms/step - loss: -0.0182 - crf_viterbi_accuracy: 0.9968 - accuracy: 0.0025 - val_loss: -0.0142 - val_crf_viterbi_accuracy: 0.9950 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.99496 to 0.99500, saving model to ner-lstmcrf2-model-0.995.hdf5\n",
      "Epoch 9/20\n",
      "34530/34530 [==============================] - 1485s 43ms/step - loss: -0.0227 - crf_viterbi_accuracy: 0.9971 - accuracy: 0.0025 - val_loss: -0.0186 - val_crf_viterbi_accuracy: 0.9949 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.99500\n",
      "Epoch 10/20\n",
      "34530/34530 [==============================] - 1465s 42ms/step - loss: -0.0271 - crf_viterbi_accuracy: 0.9972 - accuracy: 0.0025 - val_loss: -0.0218 - val_crf_viterbi_accuracy: 0.9951 - val_accuracy: 0.9951\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.99500 to 0.99509, saving model to ner-lstmcrf2-model-0.995.hdf5\n",
      "Epoch 11/20\n",
      "34530/34530 [==============================] - 1478s 43ms/step - loss: -0.0314 - crf_viterbi_accuracy: 0.9974 - accuracy: 0.0025 - val_loss: -0.0261 - val_crf_viterbi_accuracy: 0.9949 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.99509\n",
      "Epoch 12/20\n",
      "34530/34530 [==============================] - 1488s 43ms/step - loss: -0.0357 - crf_viterbi_accuracy: 0.9975 - accuracy: 0.0025 - val_loss: -0.0295 - val_crf_viterbi_accuracy: 0.9948 - val_accuracy: 0.9948\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.99509\n",
      "Epoch 13/20\n",
      "34530/34530 [==============================] - 1475s 43ms/step - loss: -0.0399 - crf_viterbi_accuracy: 0.9977 - accuracy: 0.0025 - val_loss: -0.0334 - val_crf_viterbi_accuracy: 0.9949 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.99509\n",
      "Epoch 14/20\n",
      "34530/34530 [==============================] - 1478s 43ms/step - loss: -0.0441 - crf_viterbi_accuracy: 0.9978 - accuracy: 0.0025 - val_loss: -0.0364 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.99509\n",
      "Epoch 15/20\n",
      "34530/34530 [==============================] - 1481s 43ms/step - loss: -0.0482 - crf_viterbi_accuracy: 0.9979 - accuracy: 0.0025 - val_loss: -0.0407 - val_crf_viterbi_accuracy: 0.9949 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.99509\n",
      "Epoch 16/20\n",
      "34530/34530 [==============================] - 1477s 43ms/step - loss: -0.0524 - crf_viterbi_accuracy: 0.9980 - accuracy: 0.0025 - val_loss: -0.0436 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.99509\n",
      "Epoch 17/20\n",
      "34530/34530 [==============================] - 1484s 43ms/step - loss: -0.0565 - crf_viterbi_accuracy: 0.9981 - accuracy: 0.0025 - val_loss: -0.0471 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.99509\n",
      "Epoch 18/20\n",
      "34530/34530 [==============================] - 1484s 43ms/step - loss: -0.0606 - crf_viterbi_accuracy: 0.9982 - accuracy: 0.0025 - val_loss: -0.0502 - val_crf_viterbi_accuracy: 0.9947 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.99509\n",
      "Epoch 19/20\n",
      "34530/34530 [==============================] - 1685s 49ms/step - loss: -0.0646 - crf_viterbi_accuracy: 0.9983 - accuracy: 0.0025 - val_loss: -0.0539 - val_crf_viterbi_accuracy: 0.9946 - val_accuracy: 0.9946\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.99509\n",
      "Epoch 20/20\n",
      "34530/34530 [==============================] - 1569s 45ms/step - loss: -0.0687 - crf_viterbi_accuracy: 0.9984 - accuracy: 0.0025 - val_loss: -0.0576 - val_crf_viterbi_accuracy: 0.9947 - val_accuracy: 0.9947\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.99509\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Optimiser \n",
    "adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "#Compile model\n",
    "lstmcrf2_model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
    "lstmcrf2_model.summary()\n",
    "\n",
    "#Saving the best model only\n",
    "filepath=\"ner-lstmcrf2-model-{val_accuracy:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Fit the best model\n",
    "history = lstmcrf2_model.fit(X_train, np.array(y_train), batch_size=32, epochs=20, validation_split=0.1, verbose=1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "\n",
    "#Embedding Layer\n",
    "lstmcrf2_model = Embedding(input_dim=n_words, output_dim=word_embedding_size, input_length=maxlen)(input)\n",
    "lstmcrf2_model = Dropout(0.1)(lstmcrf2_model)\n",
    "#BI-LSTM Layer\n",
    "lstmcrf2_model = Bidirectional(LSTM(units=word_embedding_size, \n",
    "                           return_sequences=True, \n",
    "                           dropout=0.5, \n",
    "                           recurrent_dropout=0.5, \n",
    "                           kernel_initializer=k.initializers.he_normal()))(lstmcrf2_model)\n",
    "lstmcrf2_model = LSTM(units=word_embedding_size * 2, \n",
    "             return_sequences=True, \n",
    "             dropout=0.5, \n",
    "             recurrent_dropout=0.5, \n",
    "             kernel_initializer=k.initializers.he_normal())(lstmcrf2_model)\n",
    "\n",
    "#TimeDistributed Layer\n",
    "lstmcrf2_model = TimeDistributed(Dense(n_tags, activation=\"relu\"))(lstmcrf2_model)  \n",
    "\n",
    "#CRF Layer\n",
    "crf = CRF(n_tags)\n",
    "\n",
    "out = crf(lstmcrf2_model)  \n",
    "\n",
    "#output\n",
    "lstmcrf2_model = Model(input, out)\n",
    "\n",
    "lstmcrf2_model.load_weights('ner-lstmcrf2-model-0.995.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592/9592 [==============================] - 210s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "test_pred = lstmcrf2_model.predict(X_test, verbose=1)   \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 83.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-art       0.00      0.00      0.00        73\n",
      "       B-eve       0.79      0.25      0.38        60\n",
      "       B-geo       0.86      0.88      0.87      7349\n",
      "       B-gpe       0.95      0.94      0.95      3165\n",
      "       B-nat       1.00      0.03      0.05        40\n",
      "       B-org       0.76      0.73      0.75      4025\n",
      "       B-per       0.87      0.80      0.83      3396\n",
      "       B-tim       0.92      0.87      0.90      4140\n",
      "       I-art       0.00      0.00      0.00        55\n",
      "       I-eve       0.40      0.09      0.15        43\n",
      "       I-geo       0.85      0.75      0.80      1505\n",
      "       I-gpe       1.00      0.59      0.75        37\n",
      "       I-nat       0.00      0.00      0.00        12\n",
      "       I-org       0.78      0.78      0.78      3228\n",
      "       I-per       0.87      0.85      0.86      3468\n",
      "       I-tim       0.85      0.71      0.77      1316\n",
      "           O       1.00      1.00      1.00   1310968\n",
      "\n",
      "    accuracy                           1.00   1342880\n",
      "   macro avg       0.70      0.55      0.58   1342880\n",
      "weighted avg       0.99      1.00      0.99   1342880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_pred=pred_labels, y_true=test_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = {}\n",
    "TN = {}\n",
    "FP = {}\n",
    "FN = {}\n",
    "for tag in tag2idx.keys():\n",
    "    TP[tag] = 0\n",
    "    TN[tag] = 0    \n",
    "    FP[tag] = 0    \n",
    "    FN[tag] = 0    \n",
    "\n",
    "def accumulate_score_by_tag(gt, pred):\n",
    "    \"\"\"\n",
    "    For each tag keep stats\n",
    "    \"\"\"\n",
    "    if gt == pred:\n",
    "        TP[gt] += 1\n",
    "    elif gt != 'O' and pred == 'O':\n",
    "        FN[gt] +=1\n",
    "    elif gt == 'O' and pred != 'O':\n",
    "        FP[gt] += 1\n",
    "    else:\n",
    "        TN[gt] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(X_test):\n",
    "    y_hat = np.argmax(test_pred[0], axis=-1)\n",
    "    gt = np.argmax(y_test[0], axis=-1)\n",
    "    for idx, (w,pred) in enumerate(zip(sentence, y_hat)):\n",
    "        accumulate_score_by_tag(idx2tag[gt[idx]], tags[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag:I-org\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:B-tim\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:I-nat\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:O\n",
      "\t TN:         0\tFP:     38368\n",
      "\t FN:         0\tTP:   2532288\n",
      "tag:I-tim\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:B-eve\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:B-geo\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:B-nat\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:B-gpe\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:     19184\n",
      "tag:I-gpe\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:B-per\n",
      "\t TN:     19184\tFP:         0\n",
      "\t FN:         0\tTP:     38368\n",
      "tag:B-art\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:I-art\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:I-eve\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:I-per\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:     38368\n",
      "tag:B-org\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n",
      "tag:I-geo\n",
      "\t TN:         0\tFP:         0\n",
      "\t FN:         0\tTP:         0\n"
     ]
    }
   ],
   "source": [
    "for tag in tag2idx.keys():\n",
    "    print(f'tag:{tag}')    \n",
    "    print('\\t TN:{:10}\\tFP:{:10}'.format(TN[tag],FP[tag]))\n",
    "    print('\\t FN:{:10}\\tTP:{:10}'.format(FN[tag],TP[tag])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Application to Input Text\n",
    "\n",
    "The model that performed the best will now be applied to our own input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac02da54f1844d28983e9ac944200ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='', description='sentence', placeholder='Type your sentence here'), Butto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact_manual\n",
    "from ipywidgets import widgets\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "#Custom Tokenizer\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "    \n",
    "def get_prediction(sentence):\n",
    "    test_sentence = tokenize(sentence) #Tokenization\n",
    "    #Preprocessing\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=word2idx[\"PAD\"], maxlen=140)\n",
    "    #Evaluation\n",
    "    p = lstmcrf2_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    #Visualisation\n",
    "    print(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\n",
    "    print(30 * \"=\")\n",
    "    for w, pred in zip(test_sentence, p[0]):\n",
    "        print(\"{:15}: {:5}\".format(w, idx2tag[pred]))\n",
    "\n",
    "interact_manual(get_prediction, sentence=widgets.Textarea(placeholder='Type your sentence here'));\n",
    "\n",
    "#text to be selected from a BBC news story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#Saving Vocab\n",
    "with open('models/word_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(word2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#Saving Vocab\n",
    "with open('models/tag_to_index.pickle', 'wb') as handle:\n",
    "    pickle.dump(tag2idx, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Potential Modifications for the Model\n",
    "\n",
    "+ Changing model hyperparameters like the number of epochs, word embedding dimensions, batch size, dropout rate, activations etc.\n",
    "+ Using a larger dataset. Here there are only 47959 sentences, which are very few to build a good model for entity recognition problem. In particular, a dataset contianing a higher proportion of the tags other than O would be beneficial to improve the model.\n",
    "+ Using pre-trained word embeddings, such as numberbatch or GloVe.\n",
    "+ Using character level embedding for LSTM in addition to word level embedding.\n",
    "+ Fine tuning of the BERT  model.\n",
    "+ Improve the vocabulary by adding unknown tokens not present in the training set in order to train the model on these tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
